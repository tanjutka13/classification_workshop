{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "import category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes) #, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.grid('off')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/bank-additional-full.csv.gz', engine='python', sep=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there are missing values in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check classes balance. Classes are pretty imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we could explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_report = ProfileReport(data)\n",
    "profile_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = profile_report.get_description()['variables'][profile_report.get_description()['variables'].type == 'NUM'].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.pairplot(data[continuous_features + ['y']], hue='y')\n",
    "handles = g._legend_data.values()\n",
    "labels = g._legend_data.keys()\n",
    "g.fig.legend(handles=handles, labels=labels, loc='lower center', ncol=2)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in continuous_features:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.boxplot(x = \"y\", y = column, data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features = list(set(profile_report.get_description()['variables'][profile_report.get_description()['variables'].type == 'CAT'].index.values) - {'y'})\n",
    "discrete_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in discrete_features:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(x='y', hue=column, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, brief data exploration has been done. let's drop duration feature as it leak from future according to data description https://archive.ics.uci.edu/ml/datasets/Bank+Marketing and go to data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('duration', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = list(set(continuous_features) - {'duration'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('y', axis=1)\n",
    "X.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['y']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17, stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Quantizer():\n",
    "    \n",
    "    def __init__(self, quantiles_num):\n",
    "        self.quantiles_num = quantiles_num\n",
    "        \n",
    "    def fit(self, feature_df):\n",
    "        self.boundaries = pd.qcut(feature_df.drop_duplicates(), q=self.quantiles_num)\n",
    "        \n",
    "    def transform(self, feature_df):\n",
    "        q_df = pd.cut(feature_df, self.boundaries.cat.categories)\n",
    "        q_df = q_df.cat.rename_categories(list(range(0, self.quantiles_num)))\n",
    "        return q_df.astype(str)\n",
    "    \n",
    "    def fit_transform(self, feature_df):\n",
    "        self.fit(feature_df)\n",
    "        q_df = self.transform(feature_df)\n",
    "        return q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quantizer = Quantizer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pdays_train = quantizer.fit_transform(X_train['pdays'])\n",
    "q_pdays_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pdays_test = quantizer.transform(X_test['pdays'])\n",
    "q_pdays_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot-encoding of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(category_encoders.OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "\n",
    "X_train_1_1 = pipeline.fit_transform(pd.concat([X_train[discrete_features], q_pdays_train], axis=1))\n",
    "X_test_1_1 = pipeline.transform(pd.concat([X_test[discrete_features], q_pdays_test], axis=1))\n",
    "\n",
    "print( X_train_1_1.shape, X_test_1_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1_1.index = list(range(X_train_1_1.shape[0]))\n",
    "X_test_1_1.index = list(range(X_test_1_1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_1_2 = pd.DataFrame(sc.fit_transform(X_train[list(set(continuous_features) - {'pdays'})]), columns=list(set(continuous_features) - {'pdays'}))\n",
    "X_test_1_2 = pd.DataFrame(sc.transform(X_test[list(set(continuous_features) - {'pdays'})]), columns=list(set(continuous_features) - {'pdays'}))\n",
    "X_train_1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = pd.concat([X_train_1_1, X_train_1_2], axis=1)\n",
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1 = pd.concat([X_test_1_1, X_test_1_2], axis=1)\n",
    "X_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace({'yes': 1, 'no': 0})\n",
    "y_test = y_test.replace({'yes': 1, 'no': 0})\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_scorer = make_scorer(f1_score, average='macro')\n",
    "skv = StratifiedKFold(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tuned_parameters = [{'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50]}]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(random_state=17, class_weight='balanced'), tuned_parameters,\n",
    "                   scoring=my_scorer, cv=skv, verbose=2, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train_1.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, clf.predict(X_test_1.values)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tuned_parameters = [{'n_neighbors': [ 3, 5, 7], \n",
    "                     'weights': ['uniform', 'distance']}]\n",
    "\n",
    "clf = GridSearchCV( KNeighborsClassifier(), tuned_parameters,\n",
    "                   scoring=my_scorer, cv=skv, verbose=2, n_jobs=-1)\n",
    "clf.fit( X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test_1)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0, 1]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with reduced feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSVD = TruncatedSVD( n_components=X_train_1.shape[1] - 1,  random_state=17).fit(X_train_1.values)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.cumsum(tSVD.explained_variance_ratio_), color='k', lw=2)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Total explained variance')\n",
    "plt.xlim(0, X_train_1.shape[1])\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.axhline(0.9, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tSVD = TruncatedSVD(n_components=21, random_state=17)\n",
    "X_train_2 = tSVD.fit_transform(X_train_1.values)\n",
    "X_test_2 = tSVD.transform(X_test_1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tuned_parameters = [{'n_neighbors': [ 3, 5, 7], \n",
    "                     'weights': ['uniform', 'distance']}]\n",
    "\n",
    "clf = GridSearchCV( KNeighborsClassifier(), tuned_parameters,\n",
    "                   scoring=my_scorer, cv=skv, verbose=2, n_jobs=-1)\n",
    "clf.fit( X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test_2)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0, 1]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = X_train_1.copy()\n",
    "X_test_3 = X_test_1.copy()\n",
    "print(X_train_3.shape, X_test_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = list(X_train_3.select_dtypes(include=['float64']))\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brute_feat_gen(df, num_col_names):\n",
    "    for name1 in tqdm_notebook(num_col_names):\n",
    "        for name2 in num_col_names:\n",
    "            df[name1 + \"_X_\" + name2] =  df[name1] * df[name2]\n",
    "            df[name1 + \"_powers3\" ] =  df[name1] * df[name1] * df[name1]\n",
    "    print( df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3_fg = brute_feat_gen(X_train_3, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_3_fg = brute_feat_gen(X_test_3, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tuned_parameters = [{'C':[0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50]}]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(random_state=17, class_weight='balanced'), tuned_parameters,\n",
    "                   scoring=my_scorer, cv=skv, verbose=2, n_jobs=-1)\n",
    "clf.fit(X_train_3_fg.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_estimator_)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test_3_fg.values)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous run of logistic regression\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "          0       0.95      0.85      0.90     10961\n",
    "          1       0.35      0.62      0.45      1392\n",
    "          /       0.88      0.83      0.85     12353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to create your own features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Local PySpark (Python-3.5 / Spark-2.1.0 )",
   "language": "python",
   "name": "py3spark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
