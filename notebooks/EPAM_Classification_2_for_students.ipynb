{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification 2.1 Reuters data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA as iPCA\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, brier_score_loss\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"reuters\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data and taking the first look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and grouped into two sets, called \"training\" and \"test\".\n",
    "This split is for training and testing algorithms that automatically detect the topic of a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters \n",
    "\n",
    " \n",
    "def collection_stats():\n",
    "    \n",
    "    # List of documents\n",
    "    documents = reuters.fileids()\n",
    "    print(str(len(documents)) + \" documents\")\n",
    " \n",
    "    train_docs = list(filter(lambda doc: doc.startswith(\"train\"),\n",
    "                        documents))\n",
    "    print(str(len(train_docs)) + \" total train documents\")\n",
    " \n",
    "    test_docs = list(filter(lambda doc: doc.startswith(\"test\"),\n",
    "                       documents));\n",
    "    print(str(len(test_docs)) + \" total test documents\")\n",
    " \n",
    "    # List of categories\n",
    "    categories = reuters.categories()\n",
    "    print(str(len(categories)) + \" categories\\n\")\n",
    " \n",
    "    # Documents in a category\n",
    "    category_docs = reuters.fileids(\"acq\")\n",
    " \n",
    "    # Words for a document\n",
    "    document_id = category_docs[0]\n",
    "    document_words = reuters.words(category_docs[0])\n",
    "    print(document_words, \"\\n\")  \n",
    " \n",
    "    # Raw document\n",
    "    print(reuters.raw(document_id))\n",
    "    \n",
    "    document_id = category_docs[1]\n",
    "    document_words = reuters.words(category_docs[1])\n",
    "    print(document_words, \"\\n\")  \n",
    " \n",
    "    # Raw document\n",
    "    print(reuters.raw(document_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See readers API descriptions\n",
    "https://www.nltk.org/api/nltk.corpus.reader.html#module-nltk.corpus.reader.api\n",
    "\n",
    "https://www.nltk.org/api/nltk.corpus.reader.html?highlight=categorizedplaintextcorpusreader#nltk.corpus.reader.CategorizedPlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "collection_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.categories()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print ids of documents in category 'barley'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print categories of 'training/9865', 'training/9880' documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate number of documents in each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    min_length = 3\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
    "    words = [word for word in words\n",
    "                  if word not in cachedStopWords]\n",
    "    tokens = (list(map(lambda token: PorterStemmer().stem(token),\n",
    "                  words)));\n",
    "    p = re.compile('[a-zA-Z]+');\n",
    "    filtered_tokens = list(filter(lambda token:\n",
    "                  p.match(token) and len(token)>=min_length,\n",
    "         tokens))\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stemmers https://pythonspot.com/nltk-stemming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return the representer, without transforming\n",
    "def tf_idf(docs):\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=3,\n",
    "                        max_df=0.90, max_features=3000,\n",
    "                        use_idf=True, sublinear_tf=True,\n",
    "                        norm='l2')\n",
    "    tfidf.fit(docs)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfIdf Sklearn API\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_values(doc, representer):\n",
    "    doc_representation = representer.transform([doc])\n",
    "    features = representer.get_feature_names()\n",
    "    return [(features[index], doc_representation[0, index])\n",
    "                 for index in doc_representation.nonzero()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_docs = []\n",
    "    test_docs = []\n",
    " \n",
    "    for doc_id in reuters.fileids():\n",
    "        if doc_id.startswith(\"train\"):\n",
    "            train_docs.append(reuters.raw(doc_id))\n",
    "        else:\n",
    "            test_docs.append(reuters.raw(doc_id))\n",
    " \n",
    "    representer = tf_idf(train_docs)\n",
    " \n",
    "    for doc in test_docs:\n",
    "        print(feature_values(doc, representer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of document ids\n",
    "documents = reuters.fileids()\n",
    " \n",
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"),\n",
    "                            documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"),\n",
    "                           documents))\n",
    " \n",
    "train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Tokenisation\n",
    "vectorizer = TfidfVectorizer(stop_words=cachedStopWords,\n",
    "                             tokenizer=tokenize)\n",
    " \n",
    "# Learn and transform train documents\n",
    "vectorised_train_documents = vectorizer.fit_transform(train_docs)\n",
    "vectorised_test_documents = vectorizer.transform(test_docs)\n",
    " \n",
    "# Transform multilabel labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform([reuters.categories(doc_id)\n",
    "                                  for doc_id in train_docs_id])\n",
    "test_labels = mlb.transform([reuters.categories(doc_id)\n",
    "                             for doc_id in test_docs_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiLabelBinarizer API\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n = vectorised_train_documents.shape[0] #how many rows we have in the dataset\n",
    "\n",
    "n_components = 2400\n",
    "chunk_size = n_components + 100\n",
    "\n",
    "ipca = iPCA(n_components=n_components) \n",
    "\n",
    "vectorised_train_documents_arr = vectorised_train_documents.toarray()\n",
    "vectorised_test_documents_arr = vectorised_test_documents.toarray()\n",
    "print(vectorised_train_documents_arr.shape)\n",
    "\n",
    "for i in tqdm_notebook(range(0, n // chunk_size)):\n",
    "    ipca.partial_fit(vectorised_train_documents_arr[i * chunk_size : (i + 1) * chunk_size])\n",
    "\n",
    "ipca.partial_fit(vectorised_train_documents_arr[(i + 1) * chunk_size:])\n",
    "    \n",
    "print(np.sum(ipca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorised_train_ipca = ipca.transform(vectorised_train_documents_arr)\n",
    "vectorised_test_ipca = ipca.transform(vectorised_test_documents_arr)\n",
    "\n",
    "print(np.shape(vectorised_train_ipca), np.shape(vectorised_train_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier_f(clf, X_train, y_train, X_test):\n",
    "    # Classifier\n",
    "    classifier = OneVsRestClassifier(clf)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    predictions = classifier.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "def eval_f(test_labels, predictions):\n",
    "    precision = precision_score(test_labels, predictions,\n",
    "                                average='micro')\n",
    "    recall = recall_score(test_labels, predictions,\n",
    "                          average='micro')\n",
    "    f1 = f1_score(test_labels, predictions, average='micro')\n",
    "\n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "            .format(precision, recall, f1))\n",
    "\n",
    "    precision = precision_score(test_labels, predictions,\n",
    "                                average='macro')\n",
    "    recall = recall_score(test_labels, predictions,\n",
    "                          average='macro')\n",
    "    f1 = f1_score(test_labels, predictions, average='macro')\n",
    "\n",
    "    print(\"Macro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "            .format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [50, 100, 200, 500]\n",
    "\n",
    "for c in tqdm_notebook(C_values):\n",
    "    \n",
    "    predictions_LR = classifier_f( LogisticRegression( C=c, random_state=42), vectorised_train_ipca, train_labels, vectorised_test_ipca)\n",
    "    print(\"C = {0:2.2f}\".format(c))\n",
    "    eval_f(test_labels, predictions_LR)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SV Classifier sclearn API\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_LinearSVC = classifier_f( LinearSVC(random_state=42), vectorised_train_documents, train_labels, vectorised_test_documents)\n",
    "eval_f(test_labels, predictions_LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_LinearSVC_ipca = classifier_f( LinearSVC(random_state=42), vectorised_train_ipca, train_labels, vectorised_test_ipca)\n",
    "eval_f(test_labels, predictions_LinearSVC_ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [ 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50, 100, 200]\n",
    "\n",
    "for c in tqdm_notebook(C_values):\n",
    "    \n",
    "    predictions_LinearSVC = classifier_f( LinearSVC( C=c, random_state=42), vectorised_train_documents, train_labels, vectorised_test_documents)\n",
    "    print(\"C = {0:2.2f}\".format(c))\n",
    "    eval_f(test_labels, predictions_LinearSVC)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kernels = [ \"rbf\", \"sigmoid\"]  \n",
    "C_values = [5e03, 1e04, 2e04, 5e04, 1e05, 2e05, 5e05]\n",
    "\n",
    "for kern in kernels:\n",
    "    for c in tqdm_notebook(C_values):\n",
    "    \n",
    "        predictions_SVC = classifier_f( SVC( C=c, kernel=kern, random_state=42), vectorised_train_documents, train_labels, vectorised_test_documents)\n",
    "        print(\"Kernel: {}, C = {:.2f}\".format(kern, c))\n",
    "        eval_f(test_labels, predictions_SVC)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_SVC_poly = classifier_f( SVC( C=1e04, gamma=0.01, kernel=\"poly\", random_state=42), vectorised_train_documents, train_labels, vectorised_test_documents)\n",
    "eval_f(test_labels, predictions_SVC_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "understanding parameters\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_GaussianNB_ipca = classifier_f( GaussianNB(), vectorised_train_ipca, train_labels, vectorised_test_ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_f(test_labels, predictions_GaussianNB_ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_GaussianNB = classifier_f(  GaussianNB(), vectorised_train_documents_arr, train_labels, vectorised_test_documents_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_f(test_labels, predictions_GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_MultinomialNB = classifier_f( MultinomialNB(), vectorised_train_documents_arr, train_labels, vectorised_test_documents_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_f(test_labels, predictions_MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_BernoulliNB = classifier_f( BernoulliNB(), vectorised_train_documents_arr, train_labels, vectorised_test_documents_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_f(test_labels, predictions_BernoulliNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run BernoulliNB with reduced by iPCA features"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Local PySpark (Python-3.5 / Spark-2.1.0 )",
   "language": "python",
   "name": "py3spark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "114px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "widgets": {
   "state": {
    "3151ff9c5f454aaa8191a238a825cd60": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
